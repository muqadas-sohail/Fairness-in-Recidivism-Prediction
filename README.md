This project aims to evaluate and quantify racial and gender biases in LLMs related to criminology, comparing them with traditional machine learning models. Performance metrics (accuracy, precision, recall, F1-score) and fairness metrics (Demographic Parity Difference, Equalised Odds Difference, Predictive Parity Difference) were used to evaluate each model. Neural Networks and BERT achieved the highest accuracy and F1-scores but also displayed significant biases. Logistic Regression and Decision Trees, while slightly less accurate, demonstrated better fairness, especially in gender-related metrics. 
